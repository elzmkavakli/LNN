# -*- coding: utf-8 -*-
"""MINSTLNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lmw9tw8cfGtTQZloDlJNahdRo8oX9yC-
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import (confusion_matrix, roc_curve, auc, f1_score, accuracy_score,
                             precision_score, recall_score)
import seaborn as sns
import pandas as pd

# MNIST veri setini yükleyin
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Veriyi normalize edin
x_train, x_test = x_train / 255.0, x_test / 255.0

# One-hot encoding fonksiyonu
def one_hot_encode(y, num_classes):
    return np.eye(num_classes)[y]

class LiquidNeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.W_in = np.random.randn(input_size, hidden_size)
        self.W_hid = np.random.randn(hidden_size, hidden_size)
        self.W_out = np.random.randn(hidden_size, output_size)
        self.bias_hid = np.zeros(hidden_size)
        self.bias_out = np.zeros(output_size)
        self.time_constant = 0.01  # Daha küçük bir değer

    def forward(self, x):
        hidden_state = np.zeros(self.hidden_size)
        outputs = []

        for t in range(len(x)):
            input_flattened = x[t].reshape(-1)
            hidden_state = (1 - self.time_constant) * hidden_state + \
                            self.time_constant * (np.dot(input_flattened, self.W_in) + self.bias_hid) + \
                            np.dot(hidden_state, self.W_hid)
            output = np.dot(hidden_state, self.W_out) + self.bias_out
            output = np.nan_to_num(output)  # NaN değerlerini 0 ile değiştir
            exp_output = np.exp(output - np.max(output))  # Numerik kararlılık için max çıkarıldı
            softmax_output = exp_output / np.sum(exp_output)
            outputs.append(softmax_output)

        return np.array(outputs), hidden_state

    def train(self, x_train, y_train, x_val, y_val, epochs=30, learning_rate=0.01):
        y_train_one_hot = one_hot_encode(y_train, self.output_size)
        y_val_one_hot = one_hot_encode(y_val, self.output_size)
        train_losses = []
        val_losses = []
        train_accuracies = []
        val_accuracies = []

        for epoch in range(epochs):
            total_loss = 0
            total_correct_train = 0

            for i in range(len(x_train)):
                # Forward pass
                predictions, hidden_state = self.forward(x_train[i:i+1])
                prediction = predictions[-1]  # Sadece son tahmini dikkate al

                # Loss hesapla (Cross-entropy loss)
                loss = -np.sum(y_train_one_hot[i] * np.log(prediction + 1e-9))
                total_loss += loss

                # Backward pass
                d_output = prediction - y_train_one_hot[i]
                d_hidden = np.dot(d_output, self.W_out.T) * self.time_constant

                # Ağırlıklar ve bias güncellemesi
                self.W_out -= learning_rate * np.outer(hidden_state, d_output)
                self.bias_out -= learning_rate * d_output

                self.W_in -= learning_rate * np.outer(x_train[i].reshape(-1), d_hidden)
                self.W_hid -= learning_rate * np.outer(hidden_state, d_hidden)
                self.bias_hid -= learning_rate * d_hidden

                # Eğitim doğruluğu hesapla
                if np.argmax(prediction) == y_train[i]:
                    total_correct_train += 1

            # Ortalama eğitim kaybını ve doğruluğunu sakla
            train_loss = total_loss / len(x_train)
            train_accuracy = total_correct_train / len(x_train)
            train_losses.append(train_loss)
            train_accuracies.append(train_accuracy)

            # Doğrulama kaybını ve doğruluğunu hesapla
            val_loss = 0
            total_correct_val = 0
            for i in range(len(x_val)):
                val_predictions, _ = self.forward(x_val[i:i+1])
                val_prediction = val_predictions[-1]
                val_loss += -np.sum(y_val_one_hot[i] * np.log(val_prediction + 1e-9))

                if np.argmax(val_prediction) == y_val[i]:
                    total_correct_val += 1

            val_loss /= len(x_val)
            val_accuracy = total_correct_val / len(x_val)
            val_losses.append(val_loss)
            val_accuracies.append(val_accuracy)

            print(f"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}")

        return train_losses, val_losses, train_accuracies, val_accuracies

    def evaluate(self, x, y):
        predictions = [self.forward(x[i:i+1])[0][-1] for i in range(len(x))]
        predicted_labels = np.argmax(predictions, axis=1)
        accuracy = accuracy_score(y, predicted_labels)
        return accuracy, predicted_labels

# Modeli oluşturun
input_size = 28 * 28  # MNIST görüntülerinin boyutu
hidden_size = 200      # Gizli katmanda nöron sayısı
output_size = 10       # MNIST'teki sınıf sayısı (0-9)
net = LiquidNeuralNetwork(input_size, hidden_size, output_size)

# Eğitim ve doğrulama verilerini ayırın
x_train_partial, y_train_partial = x_train[:40000], y_train[:40000]
x_val, y_val = x_train[40000:], y_train[40000:]

# Modeli eğitin
train_losses, val_losses, train_accuracies, val_accuracies = net.train(x_train_partial, y_train_partial, x_val, y_val, epochs=30, learning_rate=0.01)

# Eğitim ve doğrulama kayıplarını çizdirin
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Eğitim Kaybı')
plt.plot(val_losses, label='Doğrulama Kaybı')
plt.xlabel('Epoch')
plt.ylabel('Kayıp')
plt.title('Eğitim ve Doğrulama Kayıpları')
plt.legend()
plt.show()

# Eğitim ve doğrulama doğruluklarını çizdirin
plt.figure(figsize=(10, 5))
plt.plot(train_accuracies, label='Eğitim Doğruluğu')
plt.plot(val_accuracies, label='Doğrulama Doğruluğu')
plt.xlabel('Epoch')
plt.ylabel('Doğruluk')
plt.title('Eğitim ve Doğrulama Doğrulukları')
plt.legend()
plt.show()

# Test verileri üzerinde değerlendirme yapın
test_accuracy, predicted_labels = net.evaluate(x_test[:5000], y_test[:5000])
print(f"Test doğruluğu: {test_accuracy * 100:.2f}%")

# Performans metriklerini hesaplayın
conf_matrix = confusion_matrix(y_test[:5000], predicted_labels)
f1 = f1_score(y_test[:5000], predicted_labels, average='weighted')
accuracy = accuracy_score(y_test[:5000], predicted_labels)
precision = precision_score(y_test[:5000], predicted_labels, average='weighted')
recall = recall_score(y_test[:5000], predicted_labels, average='weighted')

# Sensitivity ve Specificity hesaplamaları
TP = np.diag(conf_matrix)
FP = conf_matrix.sum(axis=0) - TP
FN = conf_matrix.sum(axis=1) - TP
TN = conf_matrix.sum() - (FP + FN + TP)

sensitivity = TP / (TP + FN)
specificity = TN / (TN + FP)

# Sensitivity ve Specificity için ortalama değerler
avg_sensitivity = np.mean(sensitivity)
avg_specificity = np.mean(specificity)

# ROC Eğrisi ve AUC
y_test_one_hot = one_hot_encode(y_test[:5000], 10)
fpr, tpr, _ = roc_curve(y_test_one_hot.ravel(), np.array([pred.ravel() for pred in net.forward(x_test[:5000])[0]]).ravel())
roc_auc = auc(fpr, tpr)

# Confusion Matrix'i görselleştirin
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Tahmin Edilen Etiket')
plt.ylabel('Gerçek Etiket')
plt.show()

# ROC Eğrisi
plt.figure(figsize=(10, 7))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Eğrisi (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Yanlış Pozitif Oranı (FPR)')
plt.ylabel('Doğru Pozitif Oranı (TPR)')
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.show()

# Performans metriklerini tablo şeklinde yazdırın
metrics = {
    "Accuracy": [accuracy],
    "Precision": [precision],
    "Recall (Sensitivity)": [recall],
    "F1 Score": [f1],
    "Specificity": [avg_specificity]
}

metrics_df = pd.DataFrame(metrics)
print("\nPerformans Metrikleri:")
print(metrics_df)

# Tahmin ve gerçek etiketleri karşılaştıran bir grafik
plt.figure(figsize=(12, 6))
plt.scatter(range(len(predicted_labels)), predicted_labels, color='blue', label='Tahmin Edilen Etiketler')
plt.scatter(range(len(y_test[:5000])), y_test[:5000], color='red', label='Gerçek Etiketler', alpha=0.6)
plt.title('Tahmin Edilen ve Gerçek Etiketlerin Karşılaştırması')
plt.xlabel('Örnek')
plt.ylabel('Etiket')
plt.legend()
plt.show()